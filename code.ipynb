{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Multimodal Classification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5E0-cLkQOFp","outputId":"278fe766-e4a5-4612-fccb-f0c8e2447844"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["#@title Load libraries\n","# libraries for the files in google drive\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from pydrive.auth import GoogleAuth\n","from google.colab import drive\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","import copy\n","import re\n","import pandas as pd\n","from io import StringIO\n","import cv2\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from matplotlib import pyplot as plt, image\n","import random\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","from collections import OrderedDict\n","import warnings\n","import time\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from sklearn.metrics import classification_report\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('punkt')\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch.utils.data\n","import csv\n","import torchvision\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klYGGTFT5aqi","outputId":"04f0739c-5fe2-4fb9-f611-68e6ceb86086"},"outputs":[{"name":"stdout","output_type":"stream","text":["The download process for dataset is completed\n"]}],"source":["#@title Download content from google drive\n","# Download the dataset\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","file_id = \"1gMEr3dSoacNkSJlYnd8btBHtxEbGA6Ao\"\n","download = drive.CreateFile({'id': file_id})\n","\n","# Download the file to a local disc\n","download.GetContentFile('multi-label-classification-competition-2023.zip')\n","\n","# unzip the download file\n","!unzip -qq multi-label-classification-competition-2023.zip\n","\n","print(\"The download process for dataset is completed\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhnHD7Un5daH"},"outputs":[],"source":["#@title Utilities, models, train and validate functions\n","###############################################################################\n","# Utilities\n","\n","class DatasetArray(Dataset):\n","    r\"\"\"This is a child class of the pytorch Dataset object.\"\"\"\n","    def __init__(self, data, labels, captions, train = True):\n","        # distinguish train and test dataset\n","        if labels is not None:\n","            self.label_arr = np.asarray(labels)\n","        else:\n","            self.label_arr = None\n","        self.data_arr = np.asarray(data)\n","        self.caption_arr = np.asarray(captions)\n","        self.train = train\n","        # Pre-process image for efficient net b4\n","        if self.train:\n","          self.transform = transforms.Compose([\n","              transforms.ToPILImage(),\n","              transforms.Resize(size = (320,320), interpolation = 3),\n","              transforms.CenterCrop(size = (300,300)),\n","              transforms.ToTensor(),\n","              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                  std=[0.229, 0.224, 0.225])\n","              ])\n","        else:\n","          self.transform = transforms.Compose([\n","              transforms.ToPILImage(),\n","              transforms.Resize(size = (320,320), interpolation = 3),\n","              transforms.CenterCrop(size = (300,300)),\n","              transforms.ToTensor(),\n","              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                  std=[0.229, 0.224, 0.225])\n","              ])\n","        \n","    def __len__(self):\n","        return len(self.data_arr)\n","    \n","    def __getitem__(self, index):\n","        data = self.data_arr[index]\n","        data = self.transform(data)\n","        caption = self.caption_arr[index]\n","\n","        # if training and validation data\n","        if self.label_arr is not None:\n","            label = self.label_arr[index]\n","        \n","            return (torch.tensor(data, dtype=torch.float32), \n","                    torch.tensor(label, dtype=torch.float32), \n","                    torch.tensor(caption, dtype=torch.float32), index)\n","        # testing data\n","        else:\n","            return (torch.tensor(data, dtype=torch.float32),  \n","                    torch.tensor(caption, dtype=torch.float32), index)\n","\n","# Prepare dataloader\n","def get_loader(batch_size =128, num_workers = 1, train=True, shuffle=True, sampling=False,\n","               data=None, labels=None, captions=None):\n","    # check labels\n","    if labels is not None:\n","        labels, class_name = one_hot_encoding(labels)\n","    else:\n","        class_name = None\n","    data = DatasetArray(data = data, labels = labels, captions=captions, train = train)\n","    loader = DataLoader(\n","        data,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        num_workers=num_workers,\n","    )\n","\n","    return loader\n","\n","# Load images, captions and labels\n","def load_training_data():\n","  # Get training data dataframe\n","  train_df = read_csv_file(\"train.csv\", train = True)\n","  # Get training images\n","  train_data = get_images(train_df[\"ImageID\"])\n","  # One hot coding for training label\n","  global class_name\n","  train_label, class_name = one_hot_encoding(train_df[\"Labels\"])\n","  train_label = train_df['Labels']\n","  train_caption = proprocess_caption(train_df['Caption'])\n","\n","  return train_data, train_label, train_caption\n","\n","# Load images, captions\n","def load_testing_data():\n","  # Get testing data dataframe\n","  test_df = read_csv_file(\"test.csv\", train = False)\n","  # Get testing images\n","  test_data = get_images(test_df[\"ImageID\"])\n","  # One hot coding for training label\n","  test_caption = proprocess_test_caption(test_df['Caption'])\n","\n","  return test_data, test_caption\n","\n","# Reading the csv\n","def read_csv_file(filename, train = True):\n","  csv_list = []\n","  with open(\"COMP5329S1A2Dataset/\"+filename) as file:\n","    for line in file.readlines():\n","      if not re.match(r'^\\d+.jpg', line):\n","        continue\n","      ImageID = line.split(\",\")[0]\n","      Caption = line.split(\",\")[-1]\n","      if train:\n","        Labels = line.split(\",\")[1]\n","        Labels = [int(i) for i in Labels.split(' ')]\n","        csv_list.append({\"ImageID\":ImageID, \"Labels\": Labels, \"Caption\": Caption})\n","      else:\n","        csv_list.append({\"ImageID\":ImageID, \"Caption\": Caption})\n","    csv_df = pd.DataFrame(csv_list)\n","\n","    return csv_df\n","\n","# imbalance ratio per label\n","def IRLbl(labels):\n","    N, C = labels.shape\n","    pos_nums_per_label = np.sum(labels, axis=0)\n","    max_pos_nums = np.max(pos_nums_per_label)\n","    return max_pos_nums / pos_nums_per_label\n","\n","def MeanIR(labels):\n","    IRLbl_VALUE = IRLbl(labels)\n","    return np.mean(IRLbl_VALUE)\n","\n","def ML_ROS(all_labels, indices=None, num_samples=None, Preset_MeanIR_value=0,\n","                 max_clone_percentage=1000, sample_size=3200):\n","\n","    indices = list(range(len(all_labels))) \\\n","        if indices is None else indices\n","\n","    # if num_samples is not provided,\n","    # draw `len(indices)` samples in each iteration\n","    num_samples = len(indices) \\\n","        if num_samples is None else num_samples\n","\n","    MeanIR_value = MeanIR(all_labels) if Preset_MeanIR_value == 0 else Preset_MeanIR_value\n","    IRLbl_value = IRLbl(all_labels)\n","    # N is the number of samples, C is the number of labels\n","    N, C = all_labels.shape\n","    # the samples index of every class\n","    indices_per_class = {}\n","    minority_classes = []\n","    # accroding to psedu code, maxSamplesToClone is the upper limit of the number of samples can be copied from original dataset\n","    maxSamplesToClone = N / 100 * max_clone_percentage\n","    print('Max Clone Limit:', maxSamplesToClone)\n","    for i in range(C):\n","        ids = all_labels[:, i] == 1\n","        # How many samples are there for each label\n","        indices_per_class[i] = [ii for ii, x in enumerate(ids) if x]\n","        if IRLbl_value[i] > MeanIR_value:\n","            minority_classes.append(i)\n","\n","    new_all_labels = all_labels\n","    oversampled_ids = []\n","    minorNum = len(minority_classes)\n","    print(minorNum, 'minor classes.')\n","\n","    for idx, i in enumerate(minority_classes):\n","        tid = time.time()\n","        while True:\n","            pick_id = list(np.random.choice(indices_per_class[i], sample_size))\n","            indices_per_class[i].extend(pick_id)\n","            # recalculate the IRLbl_value\n","            # The original label matrix (New_ all_ Labels) and randomly selected label matrix (all_ labels[pick_ ID) and recalculate the irlbl\n","            new_all_labels = np.concatenate([new_all_labels, all_labels[pick_id]], axis=0)\n","            oversampled_ids.extend(pick_id)\n","\n","            newIrlbl = IRLbl(new_all_labels)\n","            if newIrlbl[i] <= MeanIR_value:\n","                print('\\nMeanIR satisfied.', newIrlbl[i])\n","                break\n","            if len(oversampled_ids) >= maxSamplesToClone:\n","                print('\\nExceed max clone.', len(oversampled_ids))\n","                break\n","            # if IRLbl(new_all_labels)[i] <= MeanIR_value or len(oversampled_ids) >= maxSamplesToClone:\n","            #     break\n","            print(\"\\roversample length:{}\".format(len(oversampled_ids)), end='')\n","        print('Processed the %d/%d minor class:' % (idx+1, minorNum), i, time.time()-tid, 's')\n","        if len(oversampled_ids) >= maxSamplesToClone:\n","            print('Exceed max clone. Exit', len(oversampled_ids))\n","            break\n","    return new_all_labels, oversampled_ids\n","\n","# Prepare oversampled dataset with given ids\n","def oversample_dataset(data,labels,captions,ids):\n","  new_data = []\n","  new_captions = []\n","  new_labels = []\n","  for id in ids:\n","    new_data.append(data[id])\n","    new_captions.append(captions[id])\n","    new_labels.append(labels[id])\n","\n","  return new_data,new_labels,new_captions\n","\n","# Embedding preprocessing\n","def remove_punctuation_re(x):\n","  x = re.sub(r'[^\\w\\s]','',x)  \n","  return x\n","\n","def tokenize_lower(x):\n","  x = x.lower()\n","  return word_tokenize(x)\n","\n","def remove_stopwords(x):\n","  stop_words = set(stopwords.words('english'))\n","  x = [word for word in x if word not in stop_words]\n","  return x\n","\n","def lemmatize(x):\n","  lemmatizer = WordNetLemmatizer()\n","  x = [lemmatizer.lemmatize(word) for word in x]\n","  return x\n","\n","def proprocess_caption(caption):\n","  caption = caption.apply(remove_punctuation_re)\n","  caption = caption.apply(tokenize_lower) \n","  caption = caption.apply(remove_stopwords) \n","  caption = caption.apply(lemmatize)\n","  # count the word frequency\n","  corpus = {}\n","  for cap in caption:\n","    for word in cap:\n","      if word not in corpus:\n","        corpus[word] = 1\n","      else:\n","        corpus[word] += 1\n","\n","  # set a threshold for the word frequency\n","  threshold = 5\n","  # set the vocab to global and use in test set\n","  global vocab\n","  vocab = [i for i in corpus if corpus[i] >= threshold]\n","  caption = caption.apply(lambda x: [word for word in x if word in vocab])\n","  caption = caption.apply(' '.join)\n","  # set the vectorizer to global and use the same vectorizer in test set\n","  global vectorizer\n","  vectorizer = TfidfVectorizer()\n","  caption = vectorizer.fit_transform(caption)\n","  global text_input\n","  text_input = caption.shape[1]\n","  return caption\n","\n","def proprocess_test_caption(caption):\n","  caption = caption.apply(remove_punctuation_re)\n","  caption = caption.apply(tokenize_lower) \n","  caption = caption.apply(remove_stopwords) \n","  caption = caption.apply(lemmatize)\n","  caption = caption.apply(lambda x: [word for word in x if word in vocab])\n","  caption = caption.apply(' '.join)\n","  # don't fit again\n","  caption = vectorizer.transform(caption)\n","  \n","  return caption\n","\n","# One hot encoding\n","def one_hot_encoding(labels):\n","    mlb = MultiLabelBinarizer()\n","    return mlb.fit_transform(labels), mlb.classes_\n","\n","# Get images\n","def get_images(image_id_list):\n","  img_path = \"COMP5329S1A2Dataset/data\"\n","  #max_height, max_width = get_image_dim()\n","  images_list = []\n","  for image_id in image_id_list:\n","    img = image.imread(os.path.join(img_path, image_id))\n","    #img = image_padding(img, max_height, max_width)\n","    images_list.append(img)\n","  return images_list\n","\n","# Get the list of class name for classification report\n","def get_class_list():\n","  global class_list\n","  class_list = []\n","  for i in class_name:\n","    class_list.append(\"class\"+str(i))\n","  return class_list\n","\n","def calculate_weighted_score(y_true, y_pred):\n","    y_pred = np.round(y_pred)\n","    f1 = f1_score(y_true, y_pred, average='micro')\n","    precision = precision_score(y_true, y_pred, average='micro')\n","    recall = recall_score(y_true, y_pred, average='micro')\n","    return f1, precision, recall\n","\n","# split the data into train and validation sets\n","def train_val_random_split(data, labels, captions, fracs=[0.8, 0.2]):\n","    assert len(fracs) == 2\n","    assert sum(fracs) == 1\n","    assert all(frac > 0 for frac in fracs)\n","    n = len(data)\n","    subset_lens = [int(n*frac) for frac in fracs]\n","    idxs = list(range(n))\n","    random.shuffle(idxs)\n","    new_data = []\n","    new_labels = []\n","    new_captions = []\n","    start_idx = 0\n","    for subset_len in subset_lens:\n","        end_idx = start_idx + subset_len\n","        cur_idxs = idxs[start_idx:end_idx]\n","        selected_data = [data[i] for i in cur_idxs]\n","        new_data.append(selected_data)\n","        selected_labels = [labels[i] for i in cur_idxs]\n","        new_labels.append(selected_labels)\n","        selected_captions = [captions[i] for i in cur_idxs]\n","        new_captions.append(selected_captions)\n","        start_idx = end_idx\n","\n","    return new_data, new_labels, new_captions\n","\n","class EarlyStopping():\n","  def __init__(self,  patience=10):\n","    self.patience = patience\n","    self.best_model = None\n","    self.best_f1 = None\n","    self.counter = 0\n","    \n","  def __call__(self, model, val_f1):\n","    # First epoch \n","    if self.best_f1 == None:\n","      self.best_f1 = val_f1\n","      self.best_model = copy.deepcopy(model)\n","    # F1-score is improving\n","    elif self.best_f1 < val_f1:\n","      self.best_f1 = val_f1\n","      self.counter = 0\n","      self.best_model.load_state_dict(model.state_dict())\n","    # F1-score is not improving\n","    elif self.best_f1 >= val_f1:\n","      self.counter += 1\n","      # If patience over the predefined limit\n","      if self.counter >= self.patience:\n","        # Restore the weight from the best model\n","        model.load_state_dict(self.best_model.state_dict())\n","        return True\n","    return False\n","\n","# Focal loss\n","def focal_bce(outputs, targets, gamma=2):\n","    l = outputs.reshape(-1)\n","    t = targets.reshape(-1)\n","    p = torch.sigmoid(l)\n","    p = torch.where(t >= 0.5, p, 1-p)\n","    logp = - torch.log(torch.clamp(p, 1e-4, 1-1e-4))\n","    loss = logp*((1-p)**gamma)\n","    loss = 18*loss.mean()\n","    return loss\n","\n","###############################################################################\n","# Models\n","###############################################################################\n","\n","# EfficientNet-b4\n","def eff_b4(pretrained=True, fine_tune=True):\n","    if pretrained:\n","        print('[INFO]: Loading pre-trained weights')\n","    else:\n","        print('[INFO]: Not loading pre-trained weights')\n","    model = models.efficientnet_b4(pretrained=pretrained)\n","    if fine_tune:\n","        print('[INFO]: Fine-tuning all layers...')\n","        for params in model.parameters():\n","            params.requires_grad = True\n","    elif not fine_tune:\n","        print('[INFO]: Freezing hidden layers...')\n","        for params in model.parameters():\n","            params.requires_grad = False\n","\n","    model.classifier[1] = nn.Sequential(\n","        nn.BatchNorm1d(num_features=1792),\n","        nn.Linear(1792, 1024),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(1024),\n","        nn.Dropout(0.4),\n","        nn.Linear(1024, 512),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(512),\n","        nn.Linear(512, 128),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(num_features=128),\n","        nn.Dropout(0.4),\n","        nn.Linear(128, 18))\n","    return model\n","\n","# text model\n","class text_branch(nn.Module):\n","    def __init__(self, input_size, dropout_rate=0.5):\n","        super(text_branch, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(input_size, 512),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(512, 18),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# Combined model\n","class image_text_net(nn.Module):\n","  def __init__(self,image_model,text_model,pretrained=True):\n","    super(image_text_net,self).__init__()\n","    self.image_model = image_model.to(device)\n","    self.text_model = text_model.to(device)\n","    self.model = nn.Sequential(\n","            nn.ReLU(),\n","            nn.Linear(36,324),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),  \n","            nn.Linear(324,108),\n","            nn.ReLU(),\n","            nn.Linear(108,18)\n","        )\n","\n","    for param in self.image_model.parameters(): \n","      param.requires_grad = False\n","    for param in self.text_model.parameters(): \n","      param.requires_grad = False\n","\n","  def forward(self,x,y):\n","    self.image_model.eval()\n","    self.text_model.eval()\n","    with torch.no_grad():\n","      output_image = self.image_model(x)\n","      output_text = self.text_model(y)   \n","    output = torch.cat((output_image,output_text),1)\n","    output = self.model(output)\n","\n","    return output\n","\n","# Train funciton for image model\n","def train(epoch, model, optimizer, criterion, train_loader, threshold = 0.5):\n","    model.train()\n","    counter = 0\n","    train_running_loss = 0.0\n","    train_running_f1 = 0.0\n","    target_list = []\n","    pred_list = []\n","    for step, (data, targets, captions, indices) in enumerate(train_loader):\n","      counter += 1\n","      data = data.to(device)\n","      targets = targets.to(device)\n","      optimizer.zero_grad()\n","      outputs = model(data)\n","      # if using focal loss, the sigmoid needs to be commented out\n","      outputs = torch.sigmoid(outputs)\n","      loss = criterion(outputs, targets)\n","      # loss = focal_bce(outputs, targets)\n","      train_running_loss += loss.item()\n","      train_running_f1 += f1_score(targets.cpu().detach().numpy(), (outputs>threshold).cpu().detach().numpy(), average='micro')\n","      loss.backward()\n","      optimizer.step()\n","        \n","    train_loss = train_running_loss / counter\n","    train_f1 = train_running_f1 / counter\n","\n","    return train_loss, train_f1\n","\n","# Validate function for image model\n","def validate(epoch, model, criterion, val_loader, is_test=False, threshold = 0.5):\n","    model.eval()\n","    counter = 0\n","    val_running_loss = 0.0\n","    val_running_f1 = 0.0\n","    target_list = []\n","    pred_list = []\n","    with torch.no_grad():\n","        for step, (data, targets, captions, indices) in enumerate(val_loader):\n","            counter += 1\n","            # prepare min_batch\n","            data = data.to(device)\n","            targets = targets.to(device)\n","            outputs = model(data)\n","            # apply sigmoid activation to get all the outputs between 0 and 1\n","            # if using focal loss, the sigmoid needs to be commented out\n","            outputs = torch.sigmoid(outputs)\n","            loss = criterion(outputs, targets)\n","            # loss = focal_bce(outputs, targets)\n","            val_running_loss += loss.item()\n","            val_running_f1 += f1_score(targets.cpu().detach().numpy(), (outputs>threshold).cpu().detach().numpy(), average='micro')\n","            # get predicted and target labels for the mini-batch\n","            pred_labels = (outputs>0.5).cpu().detach().numpy()\n","            target_labels = targets.cpu().detach().numpy()\n","            pred_list.append(pred_labels)\n","            target_list.append(target_labels)\n","            \n","        val_loss = val_running_loss / counter\n","        val_f1 = val_running_f1 / counter\n","        # compute classification report\n","        pred_list = np.concatenate(pred_list)\n","        target_list = np.concatenate(target_list)\n","        report = classification_report(target_list, pred_list, target_names= class_list)\n","        print(report)\n","        \n","        return val_loss, val_f1\n","\n","# Train and validate for text model\n","def train_validate_text(epochs, model, optimizer, criterion, train_loader, val_loader):\n","  patience = 5\n","  best_val_f1 = 0\n","  counter = 0\n","  class_names = [f'Class {i}' for i in range(1, 20) if i != 12]\n","  for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0\n","    train_running_f1 = 0\n","    val_running_f1 = 0\n","    all_outputs = []\n","    all_labels = []\n","    for step, (data, targets, captions, indices) in enumerate(train_loader):\n","      targets = targets.to(device)\n","      captions = captions.to(device)\n","      outputs = model(captions)\n","      loss = criterion(outputs, targets)   \n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      train_loss += loss.item()\n","      train_running_f1 += f1_score(targets.cpu().detach().numpy(), (outputs>0.5).cpu().detach().numpy(), average='micro')\n","    train_loss /= len(train_loader)\n","    train_f1 = train_running_f1 / len(train_loader)\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","      for step, (data, targets, captions, indices) in enumerate(val_loader): \n","        targets = targets.to(device)\n","        captions = captions.to(device)\n","        outputs = model(captions)\n","        loss = criterion(outputs, targets)   \n","        val_loss += loss.item()\n","        val_running_f1 += f1_score(targets.cpu().detach().numpy(), (outputs>0.5).cpu().detach().numpy(), average='micro')\n","        all_outputs.extend(outputs.cpu().numpy())\n","        all_labels.extend(targets.cpu().numpy())\n","    validation_loss = val_loss / len(val_loader)\n","    val_f1 = val_running_f1 / len(val_loader)\n","    y_pred_np = np.round(np.array(all_outputs))  \n","    report = classification_report(np.array(all_labels), y_pred_np, target_names=class_names)\n","    print(report)\n","    print(f'Epoch {epoch+1}/{epochs}, Training F1: {train_f1:.4f}, Validation F1:{val_f1:.4f}, Validation loss:{validation_loss:.4f}')\n","    if val_f1 > best_val_f1:\n","      print('best model saved!')\n","      counter = 0\n","      best_val_f1 = val_f1\n","      torch.save(model.state_dict(), 'text_model.pt')\n","    else:\n","      counter += 1\n","      if counter >= patience:\n","        print('Early stopping!')\n","        break\n","\n","# Train funciton for combined model\n","def train_comb(epoch, model, optimizer, criterion, train_loader, threshold = 0.5):\n","    model.train()\n","    counter = 0\n","    train_running_loss = 0.0\n","    train_running_f1 = 0.0\n","    target_list = []\n","    pred_list = []\n","    for step, (data, targets, captions, indices) in enumerate(train_loader):\n","      counter += 1\n","      data = data.to(device)\n","      targets = targets.to(device)\n","      captions = captions.to(device)\n","      optimizer.zero_grad()\n","      outputs = model(data,captions)\n","      outputs = torch.sigmoid(outputs)\n","      loss = criterion(outputs, targets)\n","      train_running_loss += loss.item()\n","      train_running_f1 += f1_score(targets.cpu().detach().numpy(), (outputs>threshold).cpu().detach().numpy(), average='micro')\n","      loss.backward()\n","      optimizer.step()\n","        \n","    train_loss = train_running_loss / counter\n","    train_f1 = train_running_f1 / counter\n","\n","    return train_loss, train_f1\n","\n","# Validate function for combined model\n","def validate_comb(epoch, model, criterion, val_loader, is_test=False, threshold = 0.5):\n","    model.eval()\n","    counter = 0\n","    val_running_loss = 0.0\n","    val_running_f1 = 0.0\n","    target_list = []\n","    pred_list = []\n","    with torch.no_grad():\n","        for step, (data, targets, captions, indices) in enumerate(val_loader):  \n","            counter += 1\n","            data = data.to(device)\n","            targets = targets.to(device)\n","            captions = captions.to(device)\n","            outputs = model(data,captions)\n","            outputs = torch.sigmoid(outputs)\n","            loss = criterion(outputs, targets)\n","            val_running_loss += loss.item()\n","            val_running_f1 += f1_score(targets.cpu().detach().numpy(), (outputs>threshold).cpu().detach().numpy(), average='micro')\n","            pred_labels = (outputs>0.5).cpu().detach().numpy()\n","            target_labels = targets.cpu().detach().numpy()\n","            pred_list.append(pred_labels)\n","            target_list.append(target_labels)\n","            \n","        val_loss = val_running_loss / counter\n","        val_f1 = val_running_f1 / counter\n","        pred_list = np.concatenate(pred_list)\n","        target_list = np.concatenate(target_list)\n","        report = classification_report(target_list, pred_list, target_names= class_list)\n","        print(report)\n","\n","    return val_loss, val_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"aSxMOedsWSp_"},"outputs":[],"source":["#@title Load data and prepare loaders\n","# Check gpu\n","global device\n","device = 'cuda' if torch.cuda.is_available() else 'cpu' \n","# Get data\n","data, labels, captions = load_training_data()\n","test_data, test_captions = load_testing_data()\n","\n","# Split training and validation set in training set\n","[train_data, val_data],[train_labels, val_labels],[train_captions, val_captions] = train_val_random_split(data, labels, captions.toarray(), fracs = [0.9,0.1])\n","\n","# Keep the same data type for testing set\n","test_captions = [np.squeeze(i.toarray()) for i in test_captions]\n","\n","# Prepare training and validation loader\n","val_loader = get_loader(batch_size = 100, num_workers = 1,\n","                          train = False, shuffle = False,\n","                          data=val_data, labels=val_labels, captions=val_captions)\n","train_loader = get_loader(batch_size = 32, num_workers = 1,\n","                          data=train_data, labels=train_labels, captions=train_captions)\n","test_loader = get_loader(batch_size = 100, num_workers = 1,\n","                          train = False, shuffle = False,\n","                          data=test_data, labels=None, captions=test_captions)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"dBiXH2gWxO1z","outputId":"529236fe-601b-475a-ec37-520ea59b944b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO]: Loading pre-trained weights\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-7eb33cd5.pth\n","100%|██████████| 74.5M/74.5M [00:04<00:00, 17.2MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["[INFO]: Freezing hidden layers...\n","              precision    recall  f1-score   support\n","\n","      class1       0.97      0.80      0.87      2293\n","      class2       0.24      0.36      0.29       111\n","      class3       0.43      0.69      0.53       426\n","      class4       0.22      0.92      0.35       142\n","      class5       0.15      0.97      0.26       110\n","      class6       0.19      0.85      0.31       120\n","      class7       0.26      0.92      0.41       108\n","      class8       0.32      0.71      0.44       215\n","      class9       0.18      0.77      0.29        91\n","     class10       0.19      0.80      0.30       119\n","     class11       0.10      0.23      0.14        65\n","     class13       0.27      0.59      0.37        66\n","     class14       0.05      0.23      0.08        31\n","     class15       0.19      0.44      0.27       199\n","     class16       0.23      0.51      0.32       108\n","     class17       0.44      0.89      0.59       144\n","     class18       0.22      0.50      0.30       157\n","     class19       0.41      0.64      0.50       110\n","\n","   micro avg       0.41      0.73      0.53      4615\n","   macro avg       0.28      0.65      0.37      4615\n","weighted avg       0.62      0.73      0.63      4615\n"," samples avg       0.54      0.79      0.60      4615\n","\n","[Epoch 1/1] Train Loss: 0.6549, Train F1: 0.2362, Validation Loss: 0.5236, Val F1: 0.5261\n"]}],"source":["#@title Train the image model\n","# To train the image model\n","torch.cuda.empty_cache()\n","# Efficient net B4\n","model = eff_b4(pretrained=True, fine_tune=False).to(device)\n","# Criterion\n","criterion = nn.BCELoss()\n","# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr= 0.0001)\n","class_list = get_class_list()\n","# initialize early_stopping (Change patience if you need to)\n","early_stopping = EarlyStopping(patience = 10)\n","best_f1 = 0\n","epochs = 1\n","# Train and validate the cnn model\n","for epoch in range(1, epochs + 1):\n","  # Train\n","  train_loss, train_f1 = train(epoch, model, optimizer, criterion, train_loader)\n","  #validation\n","  val_loss, val_f1 = validate(epoch, model, criterion, val_loader)\n","  print(f\"[Epoch {epoch}/{epochs}] Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}, Validation Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n","  if val_f1 > best_f1:\n","    best_f1 = val_f1\n","    # torch.save(model.state_dict(), \"effb3_oversample_model.pth\")\n","    torch.save(model.state_dict(), \"effb4_model.pt\")\n","  # Check early stopping  \n","  if early_stopping(model, val_f1):\n","    print(f\"Early stopping at {epoch} epoch!\")\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jN9X9EnqsjUM","outputId":"08eb0f9e-3a37-4258-c1b0-5aa0554de601"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     Class 1       0.76      1.00      0.87      2293\n","     Class 2       0.00      0.00      0.00       111\n","     Class 3       0.00      0.00      0.00       426\n","     Class 4       0.00      0.00      0.00       142\n","     Class 5       0.00      0.00      0.00       110\n","     Class 6       0.00      0.00      0.00       120\n","     Class 7       0.00      0.00      0.00       108\n","     Class 8       0.00      0.00      0.00       215\n","     Class 9       0.00      0.00      0.00        91\n","    Class 10       0.00      0.00      0.00       119\n","    Class 11       0.00      0.00      0.00        65\n","    Class 13       0.00      0.00      0.00        66\n","    Class 14       0.00      0.00      0.00        31\n","    Class 15       0.00      0.00      0.00       199\n","    Class 16       0.00      0.00      0.00       108\n","    Class 17       0.00      0.00      0.00       144\n","    Class 18       0.00      0.00      0.00       157\n","    Class 19       0.00      0.00      0.00       110\n","\n","   micro avg       0.76      0.50      0.60      4615\n","   macro avg       0.04      0.06      0.05      4615\n","weighted avg       0.38      0.50      0.43      4615\n"," samples avg       0.76      0.60      0.64      4615\n","\n","Epoch 1/1, Training F1: 0.5804, Validation F1:0.6028, Validation loss:0.1904\n","best model saved!\n"]}],"source":["#@title Train the text model\n","# To train the text model\n","# run train val on text model\n","class_list = get_class_list()\n","# Efficient net B3\n","model = text_branch(input_size=text_input).to(device)\n","# Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, amsgrad=True)\n","# Criterion\n","criterion = nn.BCELoss()\n","train_validate_text(1, model, optimizer, criterion, train_loader, val_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCh_K2LyfNQ0","outputId":"31808173-9229-437b-b8c4-90d9048e6d14"},"outputs":[{"name":"stdout","output_type":"stream","text":["[INFO]: Loading pre-trained weights\n","[INFO]: Freezing hidden layers...\n","              precision    recall  f1-score   support\n","\n","      class1       0.83      0.97      0.90      2293\n","      class2       0.00      0.00      0.00       111\n","      class3       0.66      0.29      0.41       426\n","      class4       0.00      0.00      0.00       142\n","      class5       0.99      0.68      0.81       110\n","      class6       0.00      0.00      0.00       120\n","      class7       1.00      0.05      0.09       108\n","      class8       0.25      0.00      0.01       215\n","      class9       0.00      0.00      0.00        91\n","     class10       0.00      0.00      0.00       119\n","     class11       0.00      0.00      0.00        65\n","     class13       0.00      0.00      0.00        66\n","     class14       0.00      0.00      0.00        31\n","     class15       0.00      0.00      0.00       199\n","     class16       0.00      0.00      0.00       108\n","     class17       1.00      0.33      0.49       144\n","     class18       0.00      0.00      0.00       157\n","     class19       0.00      0.00      0.00       110\n","\n","   micro avg       0.83      0.54      0.65      4615\n","   macro avg       0.26      0.13      0.15      4615\n","weighted avg       0.56      0.54      0.52      4615\n"," samples avg       0.79      0.63      0.68      4615\n","\n","[Epoch 1/1] Train Loss: 0.2608, Train F1: 0.5885, Validation Loss: 0.1527, Val F1: 0.6525\n"]}],"source":["#@title Train the combined model\n","# Train the combined model\n","torch.cuda.empty_cache()\n","\n","image_model = eff_b4(pretrained=True, fine_tune=False).to(device)\n","text_model = text_branch(input_size=text_input).to(device)\n","# Load the pre-trained model\n","image_model.load_state_dict(torch.load('effb4_model.pt'))\n","text_model.load_state_dict(torch.load('text_model.pt'))\n","\n","model = image_text_net(image_model,text_model).to(device)\n","criterion = nn.BCELoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr= 0.0001)\n","early_stopping = EarlyStopping(patience = 10)\n","best_f1 = 0\n","epochs = 1\n","# Train and validate the cnn model\n","for epoch in range(1, epochs + 1):\n","  # Train\n","  train_loss, train_f1 = train_comb(epoch, model, optimizer, criterion, train_loader)\n","  #validation\n","  val_loss, val_f1 = validate_comb(epoch, model, criterion, val_loader)\n","  print(f\"[Epoch {epoch}/{epochs}] Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f}, Validation Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n","  if val_f1 > best_f1:\n","    best_f1 = val_f1\n","    torch.save(model.state_dict(), \"model.pt\")\n","  # Check early stopping  \n","  if early_stopping(model, val_f1):\n","    print(f\"Early stopping at {epoch} epoch!\")\n","    break"]},{"cell_type":"markdown","metadata":{"id":"IecXNMT_4fCm"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
